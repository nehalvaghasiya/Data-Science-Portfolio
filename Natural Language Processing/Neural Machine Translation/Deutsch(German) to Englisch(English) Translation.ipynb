{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deutsch(German) to Englisch(English) Translation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1kjh4sLsLx1e-Eegse3QjH-kueJ-LSks5","authorship_tag":"ABX9TyP6srqDtrMqYyMkjSvJyf9C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eorxN0B4r0ip"},"source":["#Import the libraries"]},{"cell_type":"code","metadata":{"id":"3RT40Kvfrrzo","executionInfo":{"status":"ok","timestamp":1620369668776,"user_tz":-120,"elapsed":2428,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["import string\n","import re\n","from numpy import array, argmax, random, take, delete\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import ModelCheckpoint\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model\n","from keras import optimizers\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","pd.set_option('display.max_colwidth', 200)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ux9nUEIKssTC"},"source":["#Get the data"]},{"cell_type":"code","metadata":{"id":"PBbv95OVr-CX","executionInfo":{"status":"ok","timestamp":1620369671101,"user_tz":-120,"elapsed":506,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["#read raw text file\n","\n","def read_text(filename):\n","    # open the file\n","    file = open(filename, mode='rt', encoding='utf-8')\n","    \n","    # read all text\n","    text = file.read()\n","    file.close()\n","    return text"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"enRepsTTs2QZ","executionInfo":{"status":"ok","timestamp":1620369673397,"user_tz":-120,"elapsed":538,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["# split a text into sentences\n","\n","def to_lines(text):\n","    sents = text.strip().split('\\n')\n","    sents = [i.split('\\t') for i in sents]\n","    \n","    return sents"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MfTSPS4s5Zf","executionInfo":{"status":"ok","timestamp":1620369681475,"user_tz":-120,"elapsed":4291,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["#read the text data and convert into sentencce\n","\n","data = read_text(\"/content/drive/MyDrive/Colab Notebooks/natural language processing/Neural Machine Translation/deu.txt\")\n","deu_eng = to_lines(data)\n","deu_eng = array(deu_eng)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXmjGdV3v96n","executionInfo":{"status":"ok","timestamp":1620369683057,"user_tz":-120,"elapsed":470,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"c3bdffbe-47d0-4ae5-cc3f-06dc70d55fdf"},"source":["deu_eng"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['Go.', 'Geh.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n","       ['Hi.', 'Hallo!',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n","       ['Hi.', 'Grüß Gott!',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n","       ...,\n","       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n","        'Wenn jemand Fremdes dir sagt, dass du dich wie ein Muttersprachler anhörst, bedeutet das wahrscheinlich: Er hat etwas an deinem Sprechen bemerkt, dass dich als Nicht-Muttersprachler verraten hat. Mit anderen Worten: Du hörst dich nicht wirklich wie ein Muttersprachler an.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #3807493 (Tickler)'],\n","       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n","        'Wenn jemand, der nicht weiß, woher man kommt, sagt, man erwecke doch den Eindruck, Muttersprachler zu sein, so hat man Grund zu der Annahme, dass ihm an der Sprache irgendetwas aufgefallen ist, woran er erkannt hat, dass man eben keiner ist\\xa0– dass man diesen Eindruck mit anderen Worten eigentlich nicht erweckt.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #8836704 (Pfirsichbaeumchen)'],\n","       ['Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.',\n","        'Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt; wenn man jedoch in Betracht zieht, dass ein Mensch nur Gelegenheit hat, mit ein paar hundert anderen bekannt zu sein, von denen ihm nur ein Dutzend oder weniger nahesteht, darunter höchstens ein oder zwei Freunde, dann erahnt man eingedenk der Millionen Einwohner dieser Welt\\xa0leicht, dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7729416 (Pfirsichbaeumchen)']],\n","      dtype='<U537')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"kTuG4lM-tbdH","executionInfo":{"status":"ok","timestamp":1620369687802,"user_tz":-120,"elapsed":488,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["deu_eng = deu_eng[:45000,:] # using only right amount of data as per computer's computation power"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jFfcN4_Ot4M_"},"source":["#Text Preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x68PvjTJt2PG","executionInfo":{"status":"ok","timestamp":1620369691360,"user_tz":-120,"elapsed":519,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"4f40654b-8661-4d33-dad2-1d911608a6f7"},"source":["deu_eng"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['Go.', 'Geh.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n","       ['Hi.', 'Hallo!',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n","       ['Hi.', 'Grüß Gott!',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n","       ...,\n","       ['Tom is looking at me.', 'Tom sieht mich an.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #1868192 (CK) & #2133426 (Pfirsichbaeumchen)'],\n","       ['Tom is looking at us.', 'Tom sieht uns an.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #2547579 (CK) & #6642305 (Felixjp)'],\n","       ['Tom is looking tired.', 'Tom sieht müde aus.',\n","        'CC-BY 2.0 (France) Attribution: tatoeba.org #5148117 (CK) & #1937999 (Pfirsichbaeumchen)']],\n","      dtype='<U537')"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"zh-FUFUMuWW8","executionInfo":{"status":"ok","timestamp":1620369693173,"user_tz":-120,"elapsed":531,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["deu_english = delete(deu_eng, 2, 1)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9ckVL8_vfpG","executionInfo":{"status":"ok","timestamp":1620369716266,"user_tz":-120,"elapsed":1165,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["# convert to lowercase\n","for i in range(len(deu_eng)):\n","    deu_english[i,0] = deu_english[i,0].lower()\n","    \n","    deu_english[i,1] = deu_english[i,1].lower()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifP1ElsFy7z2","executionInfo":{"status":"ok","timestamp":1620369718020,"user_tz":-120,"elapsed":843,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"f27f933a-e1bb-4dae-dcb9-c60140492020"},"source":["deu_english"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['go.', 'geh.'],\n","       ['hi.', 'hallo!'],\n","       ['hi.', 'grüß gott!'],\n","       ...,\n","       ['tom is looking at me.', 'tom sieht mich an.'],\n","       ['tom is looking at us.', 'tom sieht uns an.'],\n","       ['tom is looking tired.', 'tom sieht müde aus.']], dtype='<U537')"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"lY-mq82nvoFq","executionInfo":{"status":"ok","timestamp":1620369733948,"user_tz":-120,"elapsed":920,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["# empty lists\n","eng_l = []\n","deu_l = []\n","\n","# populate the lists with sentence lengths\n","for i in deu_english[:,0]:\n","    eng_l.append(len(i.split()))\n","\n","for i in deu_english[:,1]:\n","    deu_l.append(len(i.split()))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ndSkRVWzpOx","executionInfo":{"status":"ok","timestamp":1620369748437,"user_tz":-120,"elapsed":695,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"XBZOkbN4zrKh","executionInfo":{"status":"ok","timestamp":1620369751500,"user_tz":-120,"elapsed":953,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"5fcb6be8-48ab-44b2-fee3-cd276cbbc750"},"source":["length_df.hist(bins = 30)\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ePmCF0m6zsv_","executionInfo":{"status":"ok","timestamp":1620369756468,"user_tz":-120,"elapsed":445,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["# build a tokenizer\n","\n","def tokenization(lines):\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(lines)\n","    return tokenizer"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRCkwkl0kLbp","executionInfo":{"status":"ok","timestamp":1620369842551,"user_tz":-120,"elapsed":628,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"a92d4bd0-1cb8-4eaf-bbba-9e5da4498b66"},"source":["deu_eng[:,0]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Go.', 'Hi.', 'Hi.', ..., 'Tom is looking at me.',\n","       'Tom is looking at us.', 'Tom is looking tired.'], dtype='<U537')"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXyiUUgcXWvU","executionInfo":{"status":"ok","timestamp":1620369863048,"user_tz":-120,"elapsed":1079,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"daf6c1e9-ad41-45dd-935f-467d4b1bd2a7"},"source":["# prepare english tokenizer\n","eng_tokenizer = tokenization(deu_eng[:, 0])\n","eng_vocab_size = len(eng_tokenizer.word_index) + 1\n","\n","eng_length = 8\n","print('English Vocabulary Size: %d' % eng_vocab_size)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["English Vocabulary Size: 5925\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XW8ySbvGXdMu","executionInfo":{"status":"ok","timestamp":1620369962311,"user_tz":-120,"elapsed":1230,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"88936174-b18a-4276-c80a-400011d071cb"},"source":["\n","# prepare Deutch tokenizer\n","deu_tokenizer = tokenization(deu_eng[:, 1])\n","deu_vocab_size = len(deu_tokenizer.word_index) + 1\n","\n","deu_length = 8\n","print('Deutch Vocabulary Size: %d' % deu_vocab_size)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Deutch Vocabulary Size: 9702\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-zT6U-UXXhEw","executionInfo":{"status":"ok","timestamp":1620370783171,"user_tz":-120,"elapsed":489,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["# encode and pad sequences\n","def encode_sequences(tokenizer, length, lines):\n","    # integer encode sequences\n","    seq = tokenizer.texts_to_sequences(lines)\n","    # pad sequences with 0 values\n","    seq = pad_sequences(seq, maxlen=length, padding='post')\n","    return seq"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYytfFpEXvMU"},"source":["#Train a model"]},{"cell_type":"code","metadata":{"id":"c4FxB3zLXmIK","executionInfo":{"status":"ok","timestamp":1620370787538,"user_tz":-120,"elapsed":3237,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["from sklearn.model_selection import train_test_split\n","train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)\n","\n","\n","# prepare training data\n","trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n","trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n","\n","\n","# prepare validation data\n","testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n","testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRzT2ZYCX782"},"source":["def build_model(input_vocab,output_vocab, input_length,output_length,units):\n","      model = Sequential()\n","      model.add(Embedding(input_vocab, units, input_length=input_length, mask_zero=True))\n","      model.add(LSTM(units))\n","      model.add(RepeatVector(output_length))\n","      model.add(LSTM(units, return_sequences=True))\n","      model.add(Dense(output_vocab, activation='softmax'))\n","      return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kt7qGYzUX_eF"},"source":["model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n","rms = optimizers.RMSprop(lr=0.001) # using RMSProp optimizer\n","model.compile(optimizer=rms, loss='sparse_categorical_crossentropy') #to use the target sequence as it is instead of one hot encoded format"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAyMgvvGYMSN","executionInfo":{"status":"ok","timestamp":1619804750282,"user_tz":-120,"elapsed":7225476,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"21cf5251-2202-4c9a-fcb0-2fa3a0f6d1ed"},"source":["#using ModelCheckpoint() to save the best model with lowest validation loss\n","\n","filename = 'model.parameters'\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","\n","history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n","          epochs=30, batch_size=512, \n","          validation_split = 0.2,\n","          callbacks=[checkpoint], verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","57/57 [==============================] - 233s 4s/step - loss: 4.3766 - val_loss: 2.8204\n","\n","Epoch 00001: val_loss improved from inf to 2.82036, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/30\n","57/57 [==============================] - 226s 4s/step - loss: 2.7453 - val_loss: 2.7053\n","\n","Epoch 00002: val_loss improved from 2.82036 to 2.70525, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/30\n","57/57 [==============================] - 229s 4s/step - loss: 2.6216 - val_loss: 2.5707\n","\n","Epoch 00003: val_loss improved from 2.70525 to 2.57071, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/30\n","57/57 [==============================] - 229s 4s/step - loss: 2.4346 - val_loss: 2.4120\n","\n","Epoch 00004: val_loss improved from 2.57071 to 2.41200, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 5/30\n","57/57 [==============================] - 227s 4s/step - loss: 2.2838 - val_loss: 2.3124\n","\n","Epoch 00005: val_loss improved from 2.41200 to 2.31238, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 6/30\n","57/57 [==============================] - 227s 4s/step - loss: 2.1450 - val_loss: 2.2054\n","\n","Epoch 00006: val_loss improved from 2.31238 to 2.20545, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 7/30\n","57/57 [==============================] - 226s 4s/step - loss: 2.0280 - val_loss: 2.1463\n","\n","Epoch 00007: val_loss improved from 2.20545 to 2.14629, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 8/30\n","57/57 [==============================] - 226s 4s/step - loss: 1.9033 - val_loss: 2.0392\n","\n","Epoch 00008: val_loss improved from 2.14629 to 2.03916, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 9/30\n","57/57 [==============================] - 227s 4s/step - loss: 1.8009 - val_loss: 1.9856\n","\n","Epoch 00009: val_loss improved from 2.03916 to 1.98558, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 10/30\n","57/57 [==============================] - 226s 4s/step - loss: 1.7097 - val_loss: 1.9293\n","\n","Epoch 00010: val_loss improved from 1.98558 to 1.92927, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 11/30\n","57/57 [==============================] - 226s 4s/step - loss: 1.6195 - val_loss: 1.8735\n","\n","Epoch 00011: val_loss improved from 1.92927 to 1.87345, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 12/30\n","57/57 [==============================] - 226s 4s/step - loss: 1.5259 - val_loss: 1.7934\n","\n","Epoch 00012: val_loss improved from 1.87345 to 1.79345, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 13/30\n","57/57 [==============================] - 225s 4s/step - loss: 1.4384 - val_loss: 1.7756\n","\n","Epoch 00013: val_loss improved from 1.79345 to 1.77559, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 14/30\n","57/57 [==============================] - 226s 4s/step - loss: 1.3586 - val_loss: 1.7341\n","\n","Epoch 00014: val_loss improved from 1.77559 to 1.73407, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 15/30\n","57/57 [==============================] - 227s 4s/step - loss: 1.2802 - val_loss: 1.6851\n","\n","Epoch 00015: val_loss improved from 1.73407 to 1.68507, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 16/30\n","57/57 [==============================] - 224s 4s/step - loss: 1.1976 - val_loss: 1.6457\n","\n","Epoch 00016: val_loss improved from 1.68507 to 1.64565, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 17/30\n","57/57 [==============================] - 225s 4s/step - loss: 1.1305 - val_loss: 1.6073\n","\n","Epoch 00017: val_loss improved from 1.64565 to 1.60729, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 18/30\n","57/57 [==============================] - 227s 4s/step - loss: 1.0587 - val_loss: 1.5752\n","\n","Epoch 00018: val_loss improved from 1.60729 to 1.57516, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 19/30\n","57/57 [==============================] - 227s 4s/step - loss: 0.9971 - val_loss: 1.5410\n","\n","Epoch 00019: val_loss improved from 1.57516 to 1.54104, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 20/30\n","57/57 [==============================] - 226s 4s/step - loss: 0.9303 - val_loss: 1.5112\n","\n","Epoch 00020: val_loss improved from 1.54104 to 1.51121, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 21/30\n","57/57 [==============================] - 227s 4s/step - loss: 0.8774 - val_loss: 1.4877\n","\n","Epoch 00021: val_loss improved from 1.51121 to 1.48766, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 22/30\n","57/57 [==============================] - 227s 4s/step - loss: 0.8151 - val_loss: 1.4595\n","\n","Epoch 00022: val_loss improved from 1.48766 to 1.45946, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 23/30\n","57/57 [==============================] - 228s 4s/step - loss: 0.7542 - val_loss: 1.4413\n","\n","Epoch 00023: val_loss improved from 1.45946 to 1.44129, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 24/30\n","57/57 [==============================] - 226s 4s/step - loss: 0.7085 - val_loss: 1.4318\n","\n","Epoch 00024: val_loss improved from 1.44129 to 1.43176, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 25/30\n","57/57 [==============================] - 224s 4s/step - loss: 0.6549 - val_loss: 1.4121\n","\n","Epoch 00025: val_loss improved from 1.43176 to 1.41210, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 26/30\n","57/57 [==============================] - 224s 4s/step - loss: 0.6040 - val_loss: 1.3899\n","\n","Epoch 00026: val_loss improved from 1.41210 to 1.38989, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 27/30\n","57/57 [==============================] - 223s 4s/step - loss: 0.5621 - val_loss: 1.3961\n","\n","Epoch 00027: val_loss did not improve from 1.38989\n","Epoch 28/30\n","57/57 [==============================] - 224s 4s/step - loss: 0.5179 - val_loss: 1.3601\n","\n","Epoch 00028: val_loss improved from 1.38989 to 1.36010, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 29/30\n","57/57 [==============================] - 223s 4s/step - loss: 0.4792 - val_loss: 1.3534\n","\n","Epoch 00029: val_loss improved from 1.36010 to 1.35343, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 30/30\n","57/57 [==============================] - 224s 4s/step - loss: 0.4424 - val_loss: 1.3511\n","\n","Epoch 00030: val_loss improved from 1.35343 to 1.35111, saving model to model.h1.24_jan_19\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"4c7sg40sdMC4","executionInfo":{"status":"ok","timestamp":1619804759759,"user_tz":-120,"elapsed":858,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"24fa097f-8fe8-4e33-f6aa-fdfd2539bcf5"},"source":["#compare the training loss and the validation loss\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.legend(['train','validation'])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"D9KW3Dwade-U"},"source":["#load the model and make predictions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jf24AWtFdqPs","executionInfo":{"status":"ok","timestamp":1620372448115,"user_tz":-120,"elapsed":47884,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"c4d52d77-c127-4cc8-85ad-9e1b740f7a50"},"source":["model = load_model('/content/drive/MyDrive/Colab Notebooks/natural language processing/Neural Machine Translation/model_parameters')\n","preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NeQlsztDdwYj","executionInfo":{"status":"ok","timestamp":1620375370294,"user_tz":-120,"elapsed":535,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["def get_word(n, tokenizer):\n","    for word, index in tokenizer.word_index.items():\n","        if index == n:\n","            return word\n","    return None"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1IG6wmidzaw","executionInfo":{"status":"ok","timestamp":1620375371784,"user_tz":-120,"elapsed":535,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}}},"source":["# convert predictions into text (English)\n","preds_text = []\n","for i in pred:\n","    temp = []\n","    for j in range(len(i)):\n","        t = get_word(i[j], eng_tokenizer)\n","        if j > 0:\n","            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n","                temp.append('')\n","            else:\n","                temp.append(t)\n","             \n","        else:\n","            if(t == None):\n","                temp.append('')\n","            else:\n","                temp.append(t)            \n","        \n","    preds_text.append(' '.join(temp))"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DYJL3m8d4jA"},"source":["pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vV_YHZZRd65q"},"source":["pd.set_option('display.max_colwidth', 200)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"kf13c2vmd7p5","executionInfo":{"status":"ok","timestamp":1619804988726,"user_tz":-120,"elapsed":577,"user":{"displayName":"Nehal Vaghasiya","photoUrl":"","userId":"15527123440728283390"}},"outputId":"3392341c-0468-46bc-9eee-7a0f9c168ea4"},"source":["pred_df.head(15)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>actual</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I want to resign.</td>\n","      <td>i want to</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>We're surprised.</td>\n","      <td>we're surprised</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You can't deny that.</td>\n","      <td>you can't buy that</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tell me how you feel.</td>\n","      <td>tell what i you</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Maybe it will snow.</td>\n","      <td>it may snow</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>I saw somebody.</td>\n","      <td>i saw it</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Boys are not welcome.</td>\n","      <td>hey don't be</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>She is traveling now.</td>\n","      <td>they're is</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>He wants an iPad 4.</td>\n","      <td>he wants an d</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>The woman is reading.</td>\n","      <td>the cat is brown</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>I'm my own boss.</td>\n","      <td>i'm on my boss</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>OK, wish me luck.</td>\n","      <td>i'm be in tennis</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Stop being stupid.</td>\n","      <td>stop  tom</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Tom decided to wait.</td>\n","      <td>tom forced at</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>I won't go.</td>\n","      <td>i won't going</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   actual               predicted\n","0       I want to resign.          i want to     \n","1        We're surprised.   we're surprised      \n","2    You can't deny that.  you can't buy that    \n","3   Tell me how you feel.     tell what i you    \n","4     Maybe it will snow.        it may snow     \n","5         I saw somebody.           i saw it     \n","6   Boys are not welcome.       hey don't be     \n","7   She is traveling now.        they're is      \n","8     He wants an iPad 4.       he wants an d    \n","9   The woman is reading.    the cat is brown    \n","10       I'm my own boss.      i'm on my boss    \n","11      OK, wish me luck.    i'm be in tennis    \n","12     Stop being stupid.          stop  tom     \n","13   Tom decided to wait.      tom forced at     \n","14            I won't go.      i won't going     "]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"ZBl_ZL_Z52u5"},"source":["#Summary\n","The prediction of our model can be seen on the right column. Model has been quite good, however, some results are not appropriate. It can be improved by training more epochs.\n","- I will try to train using BERT to improve accuracy."]}]}