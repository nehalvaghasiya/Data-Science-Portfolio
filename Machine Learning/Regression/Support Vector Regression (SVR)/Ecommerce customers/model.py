# -*- coding: utf-8 -*-
"""Ecommerce Customer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/108PrB9mHy4aj94RY3nqp7VdgQaEYVVRc

## Imports libraries
"""

# Commented out IPython magic to ensure Python compatibility.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""#Get the data
- Required steps to follow:
  1. Connect google-collab to google drive
  2. Arrange the files according to directory tree as shown in Readme.md
  3. Add the created model to the directory and use it in deployment.

"""

#pd.read_csv('file_name')
data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Machine learning/Regression/Linear Regression/Ecommers customers/Ecommerce Customers (1)")

data.head()

data.describe()

data.info()

"""## Exploratory Data Analysis


___
**Use seaborn to create a jointplot to compare the Time on Website and Yearly Amount Spent columns.**
"""

sns.set_palette("GnBu_d")
sns.set_style('whitegrid')

# More time on site, more money spent.
sns.jointplot(x='Time on Website',y='Yearly Amount Spent',data=data)

sns.jointplot(x='Time on App',y='Yearly Amount Spent',data=data)

y = data['Yearly Amount Spent']

X = data[['Avg. Session Length', 'Time on App','Time on Website', 'Length of Membership']]

"""#Split the train and test data"""

from sklearn.model_selection import train_test_split

#Split the data with 30% of test size

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

"""## Training the Model


"""

from sklearn.linear_model import LinearRegression

#Create an instance of a LinearRegression() model named model

model = LinearRegression()

#Train the model

model.fit(X_train,y_train)

# The coefficients
print('Coefficients: \n', model.coef_)

"""## Predicting Test Data

"""

predictions = model.predict( X_test)

"""**Create a scatterplot of the real test values versus the predicted values.**"""

plt.scatter(y_test,predictions)
plt.xlabel('Y Test')
plt.ylabel('Predicted Y')

"""## Evaluating the Model


"""

# calculate these metrics by hand!
from sklearn import metrics

print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

"""

**Plot a histogram of the residuals and make sure it looks normally distributed. Use either seaborn distplot, or just plt.hist().**"""

sns.distplot((y_test-predictions),bins=50)

coeffecients = pd.DataFrame(model.coef_,X.columns)
coeffecients.columns = ['Coeffecient']
coeffecients

"""Interpreting the coefficients:

- Holding all other features fixed, a 1 unit increase in **Avg. Session Length** is associated with an **increase of 25.98 total dollars spent**.
- Holding all other features fixed, a 1 unit increase in **Time on App** is associated with an **increase of 38.59 total dollars spent**.
- Holding all other features fixed, a 1 unit increase in **Time on Website** is associated with an **increase of 0.19 total dollars spent**.
- Holding all other features fixed, a 1 unit increase in **Length of Membership** is associated with an **increase of 61.27 total dollars spent**.


"""

#Store the model parameters using Pickle libraries

import pickle
pickle.dump(model, open('customer_model.pkl','wb'))